{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Feature Generator\n",
    "\n",
    "[Paper Inspiration](https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Xy = np.array([[1,1,1],\n",
    "              [0,0,0],\n",
    "              [1,0,0],\n",
    "              [1,0,0],\n",
    "              [1,0,1],\n",
    "              [0,1,0], \n",
    "              [0,1,0], \n",
    "              ])\n",
    "\n",
    "X = Xy[:,:2]\n",
    "y = Xy[:,2]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostedFeatureGenerator(object):\n",
    "    #TODO : Add in XGBoost/LightGBM instead of sklearn's GBC\n",
    "    #TODO : Add in any learner, not necessarily LogReg ?\n",
    "    #TODO : Enable enhanced functionality on the Train/Test split\n",
    "    \n",
    "    def __init__(self, X, y, nTrees=50):\n",
    "        \"\"\"\n",
    "        Initialize our tree builder with the number of trees needed,\n",
    "        X and y data to be trained on. We then randomly split the data,\n",
    "        train the GradientBooster and LogReg models. \n",
    "        \n",
    "        The data input should be transformed already (e.g., scaling, encoding, ...)\n",
    "        \n",
    "        INPUTS:\n",
    "        ------\n",
    "        nTrees: int = Number of trees to build our solution upon\n",
    "        X : np.array() = Training features\n",
    "        y : np.array() = Binary, 1-dimensional target vector\n",
    "        \"\"\"\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        assert(len(X)==len(y))\n",
    "        assert(nTrees>=0)\n",
    "        \n",
    "        # We do not want to try to make any predictions if the models are not trained\n",
    "        self.log_reg_built = False\n",
    "        self.tree_built = False\n",
    "        \n",
    "        # Set our maximum number of trees\n",
    "        self.nTrees = nTrees\n",
    "        \n",
    "        #42: The answer to life, the universe, everything...\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test\n",
    "        \n",
    "        # Build our GradBoost and LogReg\n",
    "        self._train_feature_trees()\n",
    "        self._train_feature_log_reg()\n",
    "        \n",
    "    def _train_feature_trees(self):\n",
    "        \"\"\"\n",
    "        Build our Gradient boosted classifier set on \n",
    "        a portion of the input data\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        \n",
    "        self.gbc = GradientBoostingClassifier(n_estimators=self.nTrees)\n",
    "        self.gbc.fit(self.X_train, self.y_train)\n",
    "        self.tree_built = True\n",
    "        # If the user wants, you can get the trained tree\n",
    "        return self.gbc\n",
    "    \n",
    "    def _train_feature_log_reg(self):\n",
    "        \"\"\"\n",
    "        Build our LogReg on the remaining fraction of the input data.\n",
    "        First, the features are generated\n",
    "        \"\"\"\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        \n",
    "        # Instantiate a LogReg model\n",
    "        self.log_reg = LogisticRegression(solver='lbfgs')\n",
    "        # Build our features from the tree\n",
    "        if self.tree_built:\n",
    "            X_gen = self.build_features(self.X_test)\n",
    "            #Train\n",
    "            self.log_reg.fit(X_gen, self.y_test)\n",
    "            self.log_reg_built = True\n",
    "        else:\n",
    "            print(\"Error: You did not build a tree first\")\n",
    "        \n",
    "        # If the user wants, you can get the trained linear model\n",
    "        return self.log_reg\n",
    "        \n",
    "    def build_features(self, X_raw):\n",
    "        \"\"\"\n",
    "        From the GBC's output, we dump out the index of the leaf nodes\n",
    "        from each classifier\n",
    "        \n",
    "        INPUTS:\n",
    "        ------\n",
    "        X_raw: np.array() = Array of the same features as `X`, but new data\n",
    "        \n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        \n",
    "        # This gives us a np.array() of each tree's leaf index output\n",
    "        leaf_node_output = self.gbc.apply(X_raw)\n",
    "        \n",
    "        # Returns the leaf indices for each tree\n",
    "        leaf_df = pd.DataFrame(leaf_node_output[:,:,0], \n",
    "                           columns=[\"leaf_index_tree\"+str(n) for n in range(self.nTrees)])\n",
    "        \n",
    "        # Now we do a One-Hot of our leaf index to provide to our linear model\n",
    "        self.leaf_df = pd.get_dummies(leaf_df.astype('category'),\n",
    "                        prefix = [\"OHE_\"+str(col) for col in leaf_df.columns])\n",
    "        \n",
    "        return self.leaf_df\n",
    "    \n",
    "    def build_predictions(self, X_input):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.tree_built and self.log_reg_built:\n",
    "            X_gen = self.build_features(X_input)\n",
    "            y_prob = self.log_reg.predict_proba(X_gen)\n",
    "        \n",
    "        #Return the scores\n",
    "        return y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple FeatGen with 3 trees\n",
    "gbc_feat = GradientBoostedFeatureGenerator(X, y, nTrees=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OHE_leaf_index_tree0_1.0</th>\n",
       "      <th>OHE_leaf_index_tree0_2.0</th>\n",
       "      <th>OHE_leaf_index_tree1_1.0</th>\n",
       "      <th>OHE_leaf_index_tree1_2.0</th>\n",
       "      <th>OHE_leaf_index_tree2_1.0</th>\n",
       "      <th>OHE_leaf_index_tree2_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OHE_leaf_index_tree0_1.0  OHE_leaf_index_tree0_2.0  \\\n",
       "0                         0                         1   \n",
       "1                         1                         0   \n",
       "2                         0                         1   \n",
       "3                         0                         1   \n",
       "4                         0                         1   \n",
       "5                         1                         0   \n",
       "6                         1                         0   \n",
       "\n",
       "   OHE_leaf_index_tree1_1.0  OHE_leaf_index_tree1_2.0  \\\n",
       "0                         0                         1   \n",
       "1                         1                         0   \n",
       "2                         0                         1   \n",
       "3                         0                         1   \n",
       "4                         0                         1   \n",
       "5                         1                         0   \n",
       "6                         1                         0   \n",
       "\n",
       "   OHE_leaf_index_tree2_1.0  OHE_leaf_index_tree2_2.0  \n",
       "0                         0                         1  \n",
       "1                         1                         0  \n",
       "2                         1                         0  \n",
       "3                         1                         0  \n",
       "4                         1                         0  \n",
       "5                         0                         1  \n",
       "6                         0                         1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you just need to build a feature set that is not necessarily tied to LogReg: Returns a Pandas DF\n",
    "gbc_feat.build_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40241641, 0.59758359],\n",
       "       [0.8265274 , 0.1734726 ],\n",
       "       [0.48789265, 0.51210735],\n",
       "       [0.48789265, 0.51210735],\n",
       "       [0.48789265, 0.51210735],\n",
       "       [0.77104928, 0.22895072],\n",
       "       [0.77104928, 0.22895072]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to use the full functionality (Trees+LogReg): Returns a NP.Array of predicted scores\n",
    "gbc_feat.build_predictions(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
